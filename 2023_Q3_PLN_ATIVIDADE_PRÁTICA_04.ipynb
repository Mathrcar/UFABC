{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mathrcar/UFABC/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 20/11 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Matheus Rocha Cardoso 11201721651`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`André Faria Guardão 11201721895`\n",
        "\n"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "Primeiro capítulo: 6\n",
        "\n",
        "Segundo capítulo: 20\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação da LIB"
      ],
      "metadata": {
        "id": "dag-jKTSFr8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# por favor, inserir o código a partir daqui...\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "RyUailD5vi9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d06ff2-537d-4fcb-f740-8cd83ba89c00"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import LIBs"
      ],
      "metadata": {
        "id": "5Uzr2h52FwGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import html"
      ],
      "metadata": {
        "id": "k6QkUqjJ-uxH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatar_saida(saida):\n",
        "   return re.sub(r'^\\s+', '', saida)"
      ],
      "metadata": {
        "id": "mr9zncX9LfV2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = userdata.get('openaiKey')"
      ],
      "metadata": {
        "id": "8aLN7Wm6-y27"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL da página web que você deseja extrair o texto\n",
        "url_cap_6 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte4/cap6/cap6.html#sec-cap6-introducao'\n",
        "url_cap_20 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap20/cap20.html'\n",
        "urls = [url_cap_6,url_cap_20]\n",
        "texto_saida = []\n",
        "\n",
        "for url in urls:\n",
        "  # Realiza uma solicitação GET para obter o conteúdo da página\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Verifica se a solicitação foi bem-sucedida\n",
        "  if response.status_code == 200:\n",
        "      # Parseia o conteúdo HTML da página usando BeautifulSoup\n",
        "      soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "      # Extrai o texto do HTML\n",
        "      texto = soup.get_text()\n",
        "\n",
        "      # Decodifica caracteres especiais, como entidades HTML\n",
        "      #texto_decodificado = html.unescape(texto)\n",
        "\n",
        "      texto_saida.append(html.unescape(texto))\n",
        "\n",
        "  else:\n",
        "      print(f'Falha na solicitação. Código de status: {response.status_code}')\n",
        "\n",
        "#imprime o texto de saida\n",
        "#print(texto_saida[1])"
      ],
      "metadata": {
        "id": "dEXwY7h1FQfD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O comando a seguir limita a quantidade de caracteres para que não passe do limite permitido para a utilização da API."
      ],
      "metadata": {
        "id": "-tAQ0U7ANOX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_final = []\n",
        "for i in range(0,2):\n",
        "  texto_final.append(texto_saida[i].replace('\\n\\n\\n\\n\\n\\n\\n\\nProcessamento de Linguagem Natural - 6\\xa0 A ordem e a função das palavras em uma sentença\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEstrutura6\\xa0 A ordem e a função das palavras em uma sentença\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProcessamento de Linguagem Natural\\n\\n\\n\\n\\n\\n\\n\\n\\n            Twitter\\n            \\n\\n\\n\\n\\n            LinkedIn\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSobre este livro\\n\\n\\n\\n\\n\\nPrefácio\\n\\n\\n\\n\\n\\nComo ler este livro\\n\\n\\n\\n\\n\\nIntrodução\\n\\n\\n\\n\\n\\n\\n\\n\\n1\\xa0 O que é PLN?\\n\\n\\n\\n\\n\\n\\n\\nFala\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\xa0 Texto ou fala?\\n\\n\\n\\n\\n\\n3\\xa0 Recursos para o processamento de fala\\n\\n\\n\\n\\n\\n\\n\\nPalavras\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\xa0 Sequência de caracteres e palavras\\n\\n\\n\\n\\n\\n5\\xa0 Expressões multipalavras\\n\\n\\n\\n\\n\\n\\n\\nEstrutura\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\xa0 A ordem e a função das palavras em uma sentença\\n\\n\\n\\n\\n\\n7\\xa0 Ferramentas e recursos para o processamento sintático\\n\\n\\n\\n\\n\\n\\n\\nSignificado\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\xa0 E o significado?\\n\\n\\n\\n\\n\\n9\\xa0 Semântica com Técnicas Simbólicas\\n\\n\\n\\n\\n\\n10\\xa0 Semântica Distribucional\\n\\n\\n\\n\\n\\n\\n\\nDiscurso\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\xa0 Modelos discursivos\\n\\n\\n\\n\\n\\n12\\xa0 Resolução de Correferência\\n\\n\\n\\n\\n\\n13\\xa0 Pragmática\\n\\n\\n\\n\\n\\n\\n\\nDados e Modelos\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\xa0 Dataset e corpus\\n\\n\\n\\n\\n\\n15\\xa0 Modelos de Linguagem\\n\\n\\n\\n\\n\\n\\n\\nAplicações\\n\\n\\n\\n\\n\\n\\n\\n\\n16\\xa0 Recuperação de Informação\\n\\n\\n\\n\\n\\n17\\xa0 Extração de Informação\\n\\n\\n\\n\\n\\n18\\xa0 Tradução Automática\\n\\n\\n\\n\\n\\n19\\xa0 Correção automática de redação\\n\\n\\n\\n\\n\\n20\\xa0 ChatGPT, MariTalk e outros agentes de conversação\\n\\n\\n\\n\\n\\n\\n\\nDomínios\\n\\n\\n\\n\\n\\n\\n\\n\\n21\\xa0 PLN na Saúde\\n\\n\\n\\n\\n\\n22\\xa0 PLN no Direito\\n\\n\\n\\n\\n\\n23\\xa0 PLN em Redes Sociais\\n\\n\\n\\n\\n\\n\\n\\nSociedade\\n\\n\\n\\n\\n\\n\\n\\n\\n24\\xa0 Questões éticas em IA e PLN\\n\\n\\n\\n\\n\\n25\\xa0 E agora, PLN?\\n\\n\\n\\n\\n\\n\\n\\nReferências\\n\\n\\n\\n\\n\\nApêndice 1 (Capítulo 2)\\n\\n\\n\\n\\n\\nSobre as/os autoras/es\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConteúdo\\n\\n6.1 Introdução\\n6.2 Reflexões Iniciais\\n6.3 Noções Básicas de Sintaxe\\n6.4 Tipos de representação\\n\\n6.4.1 Colchetes\\n6.4.2 Árvores\\n6.4.3 Setas\\n6.4.4 Parênteses\\n6.4.5 Indentação\\n\\n6.5 Sintaxe de constituência\\n\\n6.5.1 Possibilidades de interpretação e ambiguidades sintáticas\\n\\n6.6 Sintaxe de dependência\\n\\n6.6.1 Núcleo e dependente\\n6.6.2 A representação da sintaxe de dependência\\n6.6.3 Projetos de anotação multilingue: Universal Dependencies\\n\\n6.7 Qual é melhor: constituência ou dependência?\\n6.8 Fronteiras da sintaxe\\n\\n6.8.1 Sintaxe e Morfologia\\n6.8.2 Sintaxe e Semântica\\n6.8.3 Sintaxe e Pragmática\\n6.8.4 Sintaxe e Discurso\\n\\n6.9 Considerações finais\\n\\n\\n\\n\\n\\n\\n\\n6\\xa0 A ordem e a função das palavras em uma sentença\\nSintaxe\\n\\n\\n\\n\\n\\nAdriana S Pagano \\nAmanda Rassi \\nAna Clara S Pagano \\n\\n\\n\\nPublicado em:\\n\\n26/09/2023\\n\\n\\n\\n\\nPDF\\n\\n6.1 ','')[0:4090])"
      ],
      "metadata": {
        "id": "dYlvIf7bXoRB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = 'Leia o texto após os dois pontos, e faça um resumo completo do conteúdo: '"
      ],
      "metadata": {
        "id": "xVsh1x4nGvZd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = 'Leia o texto após os dois pontos, e aponte erros gramaticais presentes no se houver: '"
      ],
      "metadata": {
        "id": "3SojqL-HXUgj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = 'Leia o texto após os dois pontos, e faça a tradução do resumo do texto para o inglês: '"
      ],
      "metadata": {
        "id": "GCtK2NlRYCOP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = []\n",
        "prompts.append(prompt1)\n",
        "prompts.append(prompt2)\n",
        "prompts.append(prompt3)"
      ],
      "metadata": {
        "id": "JToYH7-qYara"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " p=1\n",
        " o=6\n",
        " for i in texto_final:\n",
        "  print(f\"TEXTO DO CAPÍTULO {o}\\n\\n\")\n",
        "  for k in prompts:\n",
        "\n",
        "    print(f'PROMPT {p}\\n')\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a kind helpful assistant.\"}]\n",
        "    messages.append({\"role\": \"user\", \"content\": k+i})\n",
        "    chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "\n",
        "    reply = chat.choices[0].message.content\n",
        "    print(f\"ChatGPT: {reply}\\n\\n\\n\")\n",
        "    p=p+1\n",
        "  p=1\n",
        "  o=20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3qBsVuGNr19",
        "outputId": "7b8e823b-3fd1-48cd-bf9a-e2c95e5e84d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTO DO CAPÍTULO 6\n",
            "\n",
            "\n",
            "PROMPT 1\n",
            "\n",
            "ChatGPT: Neste capítulo, o texto trata da subárea da linguística chamada sintaxe, que estuda como as palavras se organizam nas estruturas gramaticais das frases ou sentenças. A sintaxe é um estrato central do sistema linguístico, que organiza funções gramaticais e fornece estruturas importantes para a semântica e pragmática. A escala de ordens é uma forma de organização das unidades de análise hierarquicamente, que abrange desde os morfemas até a oração. A unidade superior de análise na língua escrita é a sentença, que consiste em um conjunto de palavras que constroem significados sobre algum evento. No PLN, é importante distinguir entre sentença e oração, pois uma sentença pode conter mais de uma oração. O capítulo aborda os níveis da escala de ordens e sua relevância para a análise sintática, incluindo a sintaxe de constituição e dependência. Além disso, discute as intersecções entre a sintaxe e os outros estratos linguísticos. O parsing sintático, que analisa a estrutura das orações, é realizado por meio de softwares chamados parsers, mas pode apresentar desafios e diferentes interpretações. O conceito de treebank também é introduzido no texto.\n",
            "\n",
            "\n",
            "\n",
            "PROMPT 2\n",
            "\n",
            "ChatGPT: O texto apresenta alguns erros gramaticais. Seguem as correções:\n",
            "\n",
            "1. O correto é \"examinadas nas distintas subáreas\", ao invés de \"examinadas nas distintas subáreas do\".\n",
            "2. O correto é \"organiza funções no estrato imediatamente inferior\", ao invés de \"organiza funções no estrato imediatamente inferior a\".\n",
            "3. O correto é \"para, por exemplo, identificar papéis temáticos cruciais\", ao invés de \"para, por exemplo, identificar papéis temáticos cruciais na tarefa de\".\n",
            "4. O correto é \"As menores unidades constitutivas das palavras\", ao invés de \"As menores unidades constitutivas das palavras, as quais, por sua vez\".\n",
            "5. O correto é \"chamadas sintagmas\", ao invés de \"chamadas sintagmas, que nos permitem\".\n",
            "6. O correto é \"conjunto organizado de palavras que constroem significados\", ao invés de \"conjunto organizado de palavras que constroem significados sobre algum\".\n",
            "7. O correto é \"escrita, há uma unidade grafológica\", ao invés de \"escrita, há uma unidade grafológica, geralmente\".\n",
            "8. O correto é \"um sinal de interrogação ou de exclamação\", ao invés de \"um sinal de interrogação e de exclamação\".\n",
            "9. O correto é \"e, portanto, mais de um evento\", ao invés de \"e, portanto, mais de um\".\n",
            "10. O correto é \"vamos abordar os níveis da escala de ordens\", ao invés de \"vamos abordar os níveis da escala de ordens e\".\n",
            "\n",
            "\n",
            "\n",
            "PROMPT 3\n",
            "\n",
            "ChatGPT: Introduction\n",
            "In the previous chapters, we saw some of the units of analysis that are examined in different subareas of linguistic studies, each of which presents specific challenges for NLP. In this chapter, our focus will be on a particular subarea - syntax - which studies how words are organized in structures that construct different grammatical functions within a sentence.\n",
            "Returning to our representation of the study of language (Figure 1.2 from Chapter 1), we can say that syntax is a central layer of the linguistic system (Figure 6.1), as it organizes functions in the immediately lower layer - morphology - and provides structures of functions that will be important in the higher layers - semantics and pragmatics - in order to, for example, identify crucial thematic roles in information extraction tasks, which answer questions like \"who?\" does \"what?\", \"for whom?\", \"how?\", \"when?\", \"where?\", etc.\n",
            "\n",
            "Figure 6.1: Representation of subareas of language study with emphasis on syntax\n",
            "\n",
            "Regarding the linguistic system, in addition to its organization in layers, we have a second form of organization: the rank scale, which organizes different units of analysis into hierarchical levels. The rank scale is represented in Figure 6.2. Morphemes are the smallest constitutive units of words, which in turn are organized into structures called phrases, which allow us to construct functions in the sentence, such as subject, objects, adjuncts, and complements.\n",
            "\n",
            "Figure 6.2: Rank scale\n",
            "\n",
            "The rank scale encompasses the units used for the description of language, whether spoken or written. The highest unit of analysis - the sentence - consists of an organized set of words that construct meanings about some event in the world, which, as we said, can be inquired about by asking questions like \"who?\" does \"what?\", \"for whom?\", \"how?\", \"when?\", \"where?\", etc.\n",
            "In written language, there is a graphological unit, usually called \"sentence\" in Portuguese, also known as \"phrase\" or \"clause\". The \"sentence\" follows the prototypical conventions of written language, that is, an initial capital letter and a punctuation mark indicating finalization, which can be a period, a question mark, or an exclamation mark. The distinction between \"sentence\" and \"clause\" is very important in NLP, since in a sentence (which begins with a capital letter and concludes with a punctuation mark) there can be more than one clause and, therefore, more than one event.\n",
            "In this chapter, we will address the levels of the rank scale and their relevance for syntactic analysis. To better understand how words function in different types of phrase and phrases in the sentence, we will present examples that we hope will be enlightening. After a section of initial reflections, we will review basic concepts of syntactic analysis, going through types of representation, until we reach the two most commonly used types of syntactic analysis in NLP: constituent syntax and dependency syntax. Finally, we will address the intersections between syntax and the other layers of the linguistic system at the end of this chapter, in Section 6.8.\n",
            "Before we move on to our initial reflections on syntax, it is worth mentioning that the process of analyzing sentence structures in NLP is called \"parsing\", a term borrowed from English. Syntactic parsing is based on the part-of-speech class of the distinct words that make up the phrases. As we will see in Chapter 7, in NLP, automatic syntactic analysis is performed using software called parsers. We will also see some challenges that analyzing syntactic constituents brings to existing parsers, especially in cases where the delimitation of units and their relationships within the sentence hierarchy allow for more than one possible interpretation.\n",
            "Another term that is important to introduce at this point is the concept of a treebank, which is used.\n",
            "\n",
            "\n",
            "\n",
            "TEXTO DO CAPÍTULO 20\n",
            "\n",
            "\n",
            "PROMPT 1\n",
            "\n",
            "ChatGPT: O capítulo 20 aborda a aplicação de agentes de conversação baseados em modelos de linguagem gerativos, como o ChatGPT e o MariTalk. Esses agentes são capazes de simular diálogos humanos e podem ser utilizados para entretenimento ou para resolver problemas específicos. O capítulo explora diferentes jogos que esses agentes podem jogar bem ou mal, incluindo sumarização, criação de história, tradução automática, escrita de e-mails, simplificação textual, perguntas sobre conteúdo pouco popular na internet, contar piadas e fazer inferências. Também são discutidas as limitações desses agentes em certas tarefas e são apresentadas conclusões provisórias sobre o assunto. Além disso, o capítulo menciona a história dos agentes de conversação, destacando o exemplo de ELIZA, um agente de conversação criado em 1966 que replicava o comportamento de um psicoterapeuta. ELIZA era baseada em padrões de conversa pré-construídos e buscava por palavras-chave nas falas das pessoas para gerar respostas.\n",
            "\n",
            "\n",
            "\n",
            "PROMPT 2\n",
            "\n",
            "ChatGPT: O texto não apresenta erros gramaticais.\n",
            "\n",
            "\n",
            "\n",
            "PROMPT 3\n",
            "\n",
            "ChatGPT: 20.1 Introduction\n",
            "ChatGPT1 and Maritalk2 (and similar ones, such as Bard3, Vicuna4, Claude5, among many others) are examples of conversational agent applications (chatbots) based on generative language models. But what does that mean?\n",
            "Some authors, like Jurafsky and Martin (Jurafsky; Martin, 2023), use the term \"conversational agent\" to define any dialogue system that communicates with users using human language and divide them into two classes: task-oriented agents, where the dialogue is to solve a specific problem, such as scheduling a trip or resolving a banking issue, while chatbots would be conversational agents that try to simulate human dialogues, more focused on entertainment. Tools like ChatGPT fit more into the second case, but they can also be embedded in other augmented tools to act as in the first case. In this chapter, the terms \"chatbots\" and \"conversational agents\" will be used interchangeably.\n",
            "Conversational agents are not new - ELIZA, created in 1966 by computer scientist Joseph Weizenbaum, was a conversational agent that replicated the behavior of a psychotherapist. ELIZA was simple, based on templates (pre-constructed conversation patterns), but could engage in long conversations by searching for certain keywords in a person's (written) speech. If a keyword was found, a rule would be applied to transform the input and create a response. In Figure 20.1, we transcribe four interactions with ELIZA (taken from (Jackson; Moulinier, 2002)).\n",
            "\n",
            "Figure 20.1: Example of interactions with the conversational agent ELIZA, created in 1966.\n",
            "\n",
            "In the excerpts, we have examples of pre-fabricated patterns that refer back to elements of the person speaking, such as \"Why do you say [...],\" \"Do you like to think that [...],\" \"What makes you think that [...],\" and \"How long have you been [...]\".\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}